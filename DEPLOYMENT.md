# Gary Bot Cloud Deployment Guide

This guide provides multiple options for deploying Gary Bot to the cloud. Choose the platform that best fits your needs.

## 🚀 Quick Deploy Options

### Option 1: Google App Engine (Recommended)
**Best for**: Easy scaling, serverless, pay-per-use

### Option 2: Streamlit Cloud
**Best for**: Free hosting, simple deployment, Streamlit-optimized

### Option 3: Railway
**Best for**: Simple deployment, good free tier

### Option 4: Google Cloud Run
**Best for**: Containerized deployment, fine-grained scaling control

---

## 📋 Prerequisites

1. **GROQ API Key**: Get your API key from [Groq Console](https://console.groq.com/)
2. **Git Repository**: Your code should be in a Git repository
3. **Cloud Platform Account**: Choose one of the platforms below

---

## 1️⃣ Google App Engine Deployment

### Setup
```bash
# Install Google Cloud CLI
# macOS: brew install google-cloud-sdk
# Or download from: https://cloud.google.com/sdk/docs/install

# Authenticate
gcloud auth login

# Create or select a project
gcloud projects create gary-bot-project  # Optional: create new project
gcloud config set project YOUR_PROJECT_ID

# Enable App Engine
gcloud app create --region=us-central1
```

### Deploy
```bash
# Set your API key
export GROQ_API_KEY="your_groq_api_key_here"

# Deploy using our script
./deploy.sh
```

**URL**: `https://YOUR_PROJECT_ID.appspot.com`

---

## 2️⃣ Streamlit Cloud Deployment

### Setup
1. Fork/push your repository to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your GitHub account
4. Select your repository

### Configuration
In Streamlit Cloud, add these **Secrets**:
```toml
GROQ_API_KEY = "your_groq_api_key_here"
LLM_MODEL = "llama3-70b-8192"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
RAG_RETRIEVAL_COUNT = "1"
DEFAULT_TEMPERATURE = "0.7"
MIN_SIMILARITY_THRESHOLD = "0.3"
```

**URL**: Automatically generated by Streamlit Cloud

---

## 3️⃣ Railway Deployment

### Setup
1. Install Railway CLI: `npm install -g @railway/cli`
2. Login: `railway login`
3. Create project: `railway new`

### Deploy
```bash
# Set environment variables
railway variables set GROQ_API_KEY=your_groq_api_key_here
railway variables set LLM_MODEL=llama3-70b-8192
railway variables set EMBEDDING_MODEL=all-MiniLM-L6-v2

# Deploy
railway up
```

**URL**: Provided by Railway after deployment

---

## 4️⃣ Google Cloud Run Deployment

### Setup
First, create a Dockerfile:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Download spaCy model
RUN python -m spacy download en_core_web_sm

# Copy application code
COPY . .

# Expose port
EXPOSE 8080

# Set environment variables
ENV PORT=8080
ENV STREAMLIT_SERVER_HEADLESS=true
ENV STREAMLIT_SERVER_ENABLE_CORS=false

# Run the application
CMD streamlit run app.py --server.port=$PORT --server.address=0.0.0.0 --server.headless=true
```

### Deploy
```bash
# Build and deploy
gcloud run deploy gary-bot \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars GROQ_API_KEY=your_groq_api_key_here,LLM_MODEL=llama3-70b-8192
```

**URL**: Provided by Cloud Run after deployment

---

## 🗄️ Data Persistence Notes

### ChromaDB Storage
- **Local Development**: Data stored in `chroma_db/` directory
- **Cloud Deployment**: Data is ephemeral by default

### Solutions for Data Persistence:

1. **Google Cloud Storage** (for GAE/Cloud Run):
   ```python
   # Add to your config
   USE_GCS_STORAGE = True
   GCS_BUCKET_NAME = "gary-bot-storage"
   ```

2. **External Vector Database**:
   - Pinecone
   - Weaviate
   - Qdrant Cloud

3. **Database Integration**:
   - Google Cloud Firestore
   - PostgreSQL with pgvector

---

## 🔧 Environment Variables

Required for all deployments:
```bash
GROQ_API_KEY=your_groq_api_key_here
LLM_MODEL=llama3-70b-8192
EMBEDDING_MODEL=all-MiniLM-L6-v2
RAG_RETRIEVAL_COUNT=1
DEFAULT_TEMPERATURE=0.7
MIN_SIMILARITY_THRESHOLD=0.3
```

---

## 📊 Monitoring & Logs

### Google App Engine
```bash
# View logs
gcloud app logs tail -s default

# View instances
gcloud app instances list

# Open app
gcloud app browse
```

### Streamlit Cloud
- Built-in logs viewer in the Streamlit Cloud dashboard
- Real-time resource monitoring

### Railway
```bash
# View logs
railway logs

# Open app
railway open
```

---

## 🛠️ Troubleshooting

### Common Issues:

1. **Memory Errors**: Increase memory in `app.yaml` or platform settings
2. **Cold Start Delays**: Consider keeping min instances > 0
3. **API Rate Limits**: Implement request queuing or rate limiting
4. **Model Download Failures**: Pre-download models during build

### Performance Optimization:

1. **Caching**: Enable Streamlit caching for embeddings
2. **Compression**: Use smaller embedding models for faster startup
3. **Lazy Loading**: Load models only when needed

---

## 💰 Cost Estimation

### Google App Engine
- **Free Tier**: 28 instance hours/day
- **Paid**: ~$0.05-0.10/hour per instance

### Streamlit Cloud
- **Free**: Unlimited public apps
- **Pro**: $20/month for private apps

### Railway
- **Free**: $5 credit/month
- **Pro**: $20/month

### Google Cloud Run
- **Free Tier**: 2 million requests/month
- **Paid**: Pay per request + CPU/memory usage

---

## 🔐 Security Best Practices

1. **API Keys**: Never commit to version control
2. **Environment Variables**: Use secure secret management
3. **Authentication**: Consider adding user authentication
4. **HTTPS**: Enabled by default on all platforms
5. **Rate Limiting**: Implement to prevent abuse

---

## 📞 Support

For deployment issues:
1. Check platform-specific documentation
2. Review application logs
3. Verify environment variables
4. Test locally first

Happy deploying! 🚀 